# 🤖 AI & 기계 학습 기초(1)

## 📚 목차

1. [AI / ML / DL 정의](#ai--ml--dl-정의)
2. [데이터 구성요소 (Feature / Label)](#데이터-구성요소-feature--label)
3. [ND 피처 기반 학습 개요](#nd-피처-기반-학습)
4. [복수 피처 기반 학습](#4-복수-피처-기반-학습)
5. [지도 학습 (Supervised Learning)](#지도-학습-supervised-learning)
6. [회귀 (Regression)](#회귀-regression)
7. [분류 (Classification)](#분류-classification)
8. [학습의 목적과 오버피팅](#학습의-목적--오버피팅)

---

## AI / ML / DL 정의

| 용어                             | 의미                                                               |
| -------------------------------- | ------------------------------------------------------------------ |
| **AI (Artificial Intelligence)** | 인간의 지능을 모방하여 학습, 추론, 문제 해결을 수행하는 기술       |
| **ML (Machine Learning)**        | 데이터로부터 학습해 패턴을 찾고 예측하는 알고리즘 (AI의 하위 분야) |
| **DL (Deep Learning)**           | 인공신경망을 이용해 복잡한 문제를 해결하는 ML의 한 분야            |

---

## 데이터 구성요소

| 구성 요소             | 설명                                        |
| --------------------- | ------------------------------------------- |
| 🧩 **Feature (특성)** | 모델에 입력되는 정보 → 예측이나 판단의 근거 |
| 🎯 **Label (정답)**   | 모델이 예측하고자 하는 목표값               |

---

## ND 피처 기반 학습

- **ND**: 학습에 사용되는 데이터가 **N차원**이라는 의미
- N = 피처의 개수
- 예: 1D, 2D, ..., ND

---

## 🔹 3-1. 1D 피처 기반 학습

- **1D** = 피처가 하나인 가장 단순한 형태의 ML 학습
- 우리가 관측할 수 있는 것은 **데이터** 뿐  
  ❌ **미지의 참 함수**와 **오차(ε)**는 관측 불가

> 🔍 **미지의 참 함수**: 입력과 출력을 연결해주는 실제 존재하는 함수 (숨겨져 있음)

### ❓ 어떤 함수가 가장 잘 설명할까?

- 여러 함수 후보들 중에서 **가장 데이터에 잘 맞는 함수**를 찾는 것이 학습!

---

## 🔹 3-2. 모델과 가설 공간

### 🧠 학습(Learning)이란?

- **데이터 D**를 이용해  
  → **가설 공간 F** 안에서  
  → 가장 적합한 함수(모델) `f`를 선택하는 것

```plaintext
D (데이터) → F (가설 공간) → f (선택된 모델)
```

> 무수히 많은 후보 함수(EX. 나는 `선형함수`들을 가설 공간으로 설정하겠어!)들 사이에서 가장 적합한 `F`를 찾는 것

## 복수 피쳐 기반 학습

## 🔹 4-1. 2D 피처 기반 학습

- 이제 피처가 2개 (예: X1, X2)
- 여전히 미지의 참 함수(surface) 와 오차는 관측 불가
  → 관측 가능한 것은 데이터 뿐

## 📌 4-2. 용어 정리

| 변수                      | 의미                           | 표기 |
| ------------------------- | ------------------------------ | ---- |
| 🎯 **Income**             | 예측하려는 값 (라벨)           | `Y`  |
| 🎓 **Years of Education** | 첫 번째 피처                   | `X1` |
| 🏢 **Seniority**          | 두 번째 피처                   | `X2` |
| ⚠️ **오차 ε**             | **피처 X와 독립이며 평균은 0** | `ε`  |

## 🤔 4-3. 왜 f를 학습하는가?

| 목적                  | 설명                                                     |
| --------------------- | -------------------------------------------------------- |
| 🔮 **예측**           | 새로운 입력값 X에서 Y 값을 예측할 수 있음                |
| 🧭 **중요 특성 파악** | 어떤 피처가 Y에 영향을 주는지 파악 가능                  |
| 🧩 **해석 가능성**    | f의 구조를 통해 각 Xi가 Y에 어떤 영향을 주는지 이해 가능 |

---

## 🤖 AI & 기계 학습 기초02

---

## 지도 학습 (Supervised Learning)

### 🔹 1-1. 지도 학습이란?

- 입력값(특성, Feature)과 정답(라벨, Label)이 주어진 데이터를 기반으로 학습하는 방식
- 목표: 주어진 입력에 대해 **올바른 출력을 예측**하는 모델 생성

---

### 🔹 1-2. 지도학습 용어

| 용어                       | 설명                      |
| -------------------------- | ------------------------- |
| 🧩 **특성 (Feature, `x`)** | 예측에 사용되는 입력 변수 |
| 🎯 **라벨 (Label, `y`)**   | 모델이 맞춰야 할 정답     |
| 📈 **예측값 (Prediction)** | 모델이 출력한 결과        |
| ⚠️ **오류 (Error)**        | `오류 = 예측값 - 라벨`    |

---

## 회귀 (Regression)

### 🔹 2-1. 회귀 문제

- 입력에 대해 **연속적인 숫자 값**을 예측하는 문제
- 예: 집값, 온도, 키, 무게 등 예측

---

### 🔹 2-2. 회귀 오류: MSE (Mean Squared Error)

- **정의**  
  모든 샘플의 `(정답 - 예측)^2` 의 평균

- **해석**  
  ❗ 큰 오류일수록 **더 큰 패널티** → 전체 예측의 오류 수준을 파악 가능

---

### 🔹 2-3. 회귀 설명력: R² (결정계수)

| 항목        | 설명                                                 |
| ----------- | ---------------------------------------------------- |
| 📐 **정의** | R² = 1 - (실제값-예측값)² 합 / (실제값 - 평균값)² 합 |
| 🧠 **의미** | 라벨의 분산 중 특성으로 설명 가능한 비율             |
| 🎯 **해석** | R² → 1에 가까울수록 모델의 설명력이 높음             |

> ❓ **R²가 음수가 될 수 있을까?**  
> ✔️ **될 수 있다!** 평균값으로 예측하는 것보다 못한 경우 → 가설 공간 잘못 설정했을 가능성

---

## 분류 (Classification)

### 🔹 3-1. 분류 문제

- 입력으로부터 **범주(클래스)**를 예측
- 예: 이메일 → 스팸 / 정상

---

### 🔹 3-2. 분류 정확도 (Accuracy)

- **정확도 = 전체 중 맞춘 비율**

❗ **문제점**:

- **데이터가 불균형한 경우**, 정확도만으로 모델 성능 판단 X  
  예: 양성 1%, 음성 99% → 무조건 음성이라 해도 정확도 99% ❌

---

### 🔹 3-3. 혼동 행렬 (Confusion Matrix)

| 실제값 →<br>예측값 ↓ | 양성 (Positive) | 음성 (Negative) |
| -------------------- | --------------- | --------------- |
| 양성으로 예측        | ✅ TP           | ❌ FP           |
| 음성으로 예측        | ❌ FN           | ✅ TN           |

#### 📊 주요 지표

| 지표                      | 계산식                                          | 의미                          |
| ------------------------- | ----------------------------------------------- | ----------------------------- |
| 🎯 **정밀도 (Precision)** | TP / (TP + FP)                                  | 예측한 양성 중 실제 양성 비율 |
| 🔁 **재현율 (Recall)**    | TP / (TP + FN)                                  | 실제 양성 중 예측 성공 비율   |
| ⚖️ **F1-score**           | 2 × (Precision × Recall) / (Precision + Recall) | 정밀도와 재현율의 조화 평균   |

> ✅ F1-score, 정밀도, 재현율 모두 **높을수록 좋은 모델!**

---

## 학습의 목적 & 오버피팅

### 🔹 4-1. 학습의 목적

- 목표: **일반화** 잘하는 모델 만들기  
  → **테스트 데이터(처음 보는 데이터)**에 대해서도 성능이 좋게!

- **일반화 (Generalization)**  
  → 훈련되지 않은 새로운 데이터에 대해서도 **낮은 오류 유지**

---

### 🔹 4-2. 오버피팅 (Overfitting)

- 훈련 데이터에 **너무 과하게 맞춘 모델**
- 테스트 데이터 성능 저하 → **일반화 실패**

#### ⚠️ 왜 문제인가?

| 원인/결과          | 설명                                        |
| ------------------ | ------------------------------------------- |
| 🧪 **표본 의존**   | 훈련 데이터에 포함된 우연한 잡음까지 학습함 |
| 📉 **일반화 실패** | 테스트 데이터 오류 증가 → 실전 사용 불가    |

#### 오버피팅에 대한 오해

> ❌ 오버피팅 ≠ 분포 변화(Distribution Shift)

| 항목                  | 설명                                                               |
| --------------------- | ------------------------------------------------------------------ |
| 🔄 **분포 변화**      | 훈련 데이터와 테스트 데이터의 분포가 **다를 때** 발생              |
| 📉 **성능 저하 이유** | 환경 변화, 계절성, 센서 교체 등으로 인해 **테스트 성능 하락** 가능 |
| ⚠️ **중요 포인트**    | **오버피팅이 없어도** 분포 변화 때문에 오류는 증가할 수 있음       |

> 📌 오버피팅은 **복잡한 모델이 훈련 데이터에 과하게 맞춘 상태**
> 분포 변화는 **데이터 환경 자체가 달라진 것**이므로 **서로 다른 개념**

#### 오버피팅 vs 언더피팅(균형 잡기)

| 구분            | 설명                                                       | 결과                       |
| --------------- | ---------------------------------------------------------- | -------------------------- |
| 🧠 **오버피팅** | 모델이 **너무 복잡**해서 훈련 데이터의 **잡음까지 학습**함 | 테스트 성능 **저하**       |
| 💤 **언더피팅** | 모델이 **너무 단순**하거나 충분히 학습되지 않음            | 훈련/테스트 **둘 다 나쁨** |

> 🔄 **균형 잡기(Trade-off)**가 중요

> ✅ 해결을 위한 전략 :
> 더 많은 데이터, 테스트 데이터를 활용한 모델 선정, 교차 검증 필요

---
