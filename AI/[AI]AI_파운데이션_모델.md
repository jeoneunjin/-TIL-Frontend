# 🤖 AI & 기계학습 방법론(2)

## 📚 목차

- ***

---

## 1. AI 파운데이션 모델

### 1-1. AI 파운데이션 모델 개념

- AI 파운데이션 모델? = AI 모델

  > - 함수 또는 프로그램
  > - 입출력을 연결해주는 함수 + 데이터로 학습된 함수 + 학습 때 보지 못했던 데이터에 대해서도 작동해야하는 의무
  > - 예시 : 뉴럴넷 | 입력 -> 뉴럴넷 -> 출력

- 현실적인 기계학습 모델
  > - 학습 = AI 모델에 데이터를 **패턴화** 하여 압축
  > - 이 과정에서 **비슷함**과 **다름**을 파악, 패턴을 익히면서 새로운 데이터에 대한 **일반화** 능력이 생김

* 이상적인 AI를 위해 세상의 수만은 데이터를 최대한 기억할 수 있다면?

#### 파운데이션 모델이란?

> **대규모 데이터**를 폭넓게 학습한 후, 다양한 문제에 빠르게 적응할 수 있는 범용 대형 AI 모델

#### 기존 딥러닝 개발 패러다임 vs 파운데이션 모델 패러다임

| 기존                                                                   | 파운데이션                                                      |
| ---------------------------------------------------------------------- | --------------------------------------------------------------- |
| 아기와 같이 언어, 시각, 청각, 촉각 등 기본적인 것들부터 배워 나가야 함 | 거대 모델(커다란 뇌) + 대규모 데이터 학습(많은 지식과 경험)기반 |

- 파운데이션 모델이 새로운 일을 처음 접해도 금방 배우고 잘할 수 있음

#### 특징

1. 대규모
   > 트랜스포머 모델 + 대규모 언어 데이터 학습
   - 테스크에 상관없이 비슷한 패턴들이 등장하고 있음
   - 주로 비지도학습으로 훈련된 모델들도 많은 등장
2. 적용성
   > 높은 파인튜닝 성능(높은 태스크 적응 성능)
   - (특정 패턴 학습 전)기본적인 상태에도 사용할 수 있는
   - 믿고 쓸 수 있는 모델
3. 범용성
   > 다양한 작업, 한정되지 않는 출력 지원
   - Ex. 물체 파별
     - 기존 : 20개의 물체 종류 구분
     - 파운데이션 : 만 개 이상 물체 종류 구분(또는 자연어 기반의 한정되지 않은 대상에 대한 인식)

#### AI 모델 개발의 변화

- 과거에는 매번 모델을 새로 학습 <> 이제는 잘 학습된 모델들을 얼마나 잘 활용하냐가 핵심
- 적응 활용
  - 활용 되는 기법들: 프롬프트{엔지니어링, 튜닝}, 전이학습, 적응학습, 파인튜닝
    > - Zero-shot : 처음 보는 문제를 추가 학습 없이 바로 적용(모델 자체가 가진 배경 지식 활용)
    > - Few-shot : 예제 몇 개만 보여주면 바로 적용 가능
    > - Fine-tuning : 처음부터 배우지 않아도, 조금만 알려주면 금방 적용(모델 자체를 업데이트, 모델 가중치가 변경 됨)

### 1-2. 대표적 AI 파운데이션 모델

### 1. CLIP

? 사고 능력과 언어 능력만으로 현실 세계를 이해하기에 충분할까
-> 눈을 달아보자!
=> 시각언어모델

#### 시각언어 모델 예시

- ChatGPT with GPT-4
  - 자연어 입력에 국한된 기존의 거대 언어 모델에서 더 나아가 이미지, 문서, 음성 등 **멀티모달** 데이터를 처리할 수 있는 모델
- Computer use, Claude

#### CLIP(Contrastive Language-Image Pre-training)

> 이게 바로 눈 역할!
> AI가 언어와 시각을 통합해서 이해하는 방식을 보여준 패러다임 전환 제시

- 특징 :
  - 입력 : 학습하지 않은 새로운 도메인의 입력 데이터에 대해서도 좋은 성능을 발휘(제로샷 전이)
  - 출력 : 자연어를 이용해 한번도 본적 없는 카테고리도 텍스트 설명만으로 출력 정의 가능(언어 인터페이스)
  - 대조 학습 기반의 언어-이미지 사전학습

#### 대조 학습 기반의 언어-이미지 학습

- 인터넷 데이터를 통한 지도 학습(supervise learning)을 통해 자연어 기반 시각 개념 학습
- 다양한 이미지-자연어 쌍으로 학습
  - 데이터 정제 과정을 거침(중복 이미지, 해상도/품질 낮은 이미지, 짧은 텍스트 등)
  - 텍스트 인코더 : Transformer
  - 이미지 인코더 : ViT0B(또는 ResNet50)

#### CLIP 구조 - 텍스트 인코더(Transformer 기반 Text Encoder)

#### CLIP 구조 - 이미지 인코더(Transformer 기반 Text Encoder)

#### CLIP 학습

- **대조 학습**
- **학습 기준**
  - 목표 이미지(앵커)를 대응하는 텍스트(양성)와 가깝게
  - 일치하지 않는 여러 텍스트(음성)와는 멀게
- softmax?

  $$
  \text{Softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{n} e^{z_j}}
  $$

  > Softmax는 입력 벡터 $z$를 받아서 각 원소를 0~1 사이 값으로 바꾸고, 전체 합이 1이 되도록 정규화(normalize)
  > 이미지-텍스트 간의 유사도 $s_ij$를 확률처럼 바꾸는 역할을 함

$$
\mathcal{L}_{\text{CLIP}} = \frac{1}{2}
\left(
-\frac{1}{N} \sum_{i=1}^{N} \log
\frac{e^{s_{ii}/\tau}}{\sum_{j=1}^{N} e^{s_{ij}/\tau}}
+
-\frac{1}{N} \sum_{i=1}^{N} \log
\frac{e^{s_{ii}/\tau}}{\sum_{j=1}^{N} e^{s_{ji}/\tau}}
\right)
$$

#### CLIP 간단 응용

- 제로샷 이미지 인식기
  - 텍스트로 원하는 물체 카테고리 리스트 준비
  - 텍스트 기반 카테고리 리스트를 텍스트 임베이딩으로 변환하여 Vector DB 준비
  - 쿼리 이미지와 비교해서 가장 높은 점수의 카데고리 반환

? 생각해보기

- 검색 시스템과 유사성은 무엇일까?
- 카테고리 이외의 어떤 것이 가능할까?
- 카데고리가 정말 많을 경우에 어떻게 효율화 할까?

---

## 2. VLM(Vision-Language Model)

### 2-1. SigLIP

> softmax 대신 sigmoid 기반 손실함수

- 기존 CLIP에서 사용한 대조학습의 한계
  - CLIP의 대조학습(contrastive learning) 은 모든 음성(또는 비일치 쌍, negative pairs)에 대해 거리를 계속 벌리려는 경향이 있음
  - SigCLIP은 이런 한계를 완화하려고, 너무 멀리 떨어진 음성 데이터는 무시하고 양성 쌍(positive pairs) 중심으로 학습하도록 손실을 수정함
    > → 즉, 불필요한 음성 샘플에 대한 gradient 낭비를 줄임.

#### 멀티 모달 정합 응용

#### 멀티모달 정합(Multi-modal Alignment)

- 서로 다른 두 가지 이상의 모달리티 간의 공통된 임베이딩 벡터 공간을 구성하는 것
- 서로 다른 모달리티 임베이딩 간 유사도 비교 가능
- 대표적인 모델:
  - CLIP(OpenAI)
  - ImageBind(Meta)
    이미지, 비디오, 텍스트 오디오, 뎁스, 열화상, IMU 모달리티 공간을 공유하도록 학습

---

### 2-2. 멀티모달 언어 모델

- 이미지, 소리, 비디오 등 다양한 모달리티를 함께 이해하고 처리할 수 있는 언어 모델

1. LLaVA(Large Language and Vision Assistant)

- Vision과 Language 모델을 결함한 모델(VLM)로, 텍스트와 이미지를 동시에 이해
- 주요 특징
  - 이미지 인식과 텍스트 생성을 결합하여, 이미지 설명 생성 또는 시각적 질문 응답 작업에서 뛰어난 성능
  - 이미지, 명령, 답변이 주어진 데이터셋을 구축하여 Instruction tuning으로 학습
  - 효율적인 메모리 사용
  - 다중 모달 학습
  - Fine-tuning
- 응용 사례
  - 이미지 기반 질문 응답
  - 이미지 설명 생성
  - 시각적 정보 기반 대화 등

#### Step1 : 사전 학습

#### Step2 : Fine-tuning

#### LLaVa 학습 데이터

**_최신 공개 VLM 모델들_**

2. Qwen-VL(Alibaba)

- 알리바바에서 개발한 대형 멀티모달 모델
- Qwen-LM이라는 텍스트 기반 대형 언어 모델(LLM)에 시각 처리 능력을 부여해, 이미지 텍스트를 동시에 이해하는 모델
- 여러 개의 이미지 입력, 번역, 텍스트 읽기, 위치 찾기(물체 탐지), 인식, 이해 능력이 있음

3. Qwen-VL 확장
   3-1. Qwen2-VL
   3-2. Qwen2.5-VL
   3-2. Qwen2.5-Omni
   3-1. Qwen3-VL

4. InternVL

- LLM의 대규모 용량에 맞추어 이미지 모델의 용량을 증대시킴
- 학습 전략
  (a) 단일 모델 학습 파이프라인
  (b) LLM을 점점 키워가면서 학습하는 파이프라인

---

### 2-3. VLM 성능을 높이는 트릭

> Set of Mark(SoM)

- 다른 물체 탐지, 세그멘테이션 파운데이션 모델을 활용한 방법
- VLM 모델들의 부족한 시각 능력을 보완하여 비약적 성능 향상
- Computer 작동 Agent 모델에 기본적인 비주얼 프롬프팅으로 매우 유용

### 2-4. 도메인 특화 파운데이션 모델들

#### 의료

#### 제조업

#### 3D 언어 모델

#### 로봇 행동 모델

---

### 2-5. 심화. CLIP 모델의 고급 응용

#### 멀티 모달 정합 손실함수로 활용

- 서로 다른 모달리티 간의 변환

- 밀티모달 정합을 활용하는 법

- 정합을 통한 크로스모달 변환

  > 단일 데이터에 대해서만 학습 = 최적화(학습 X)

  - backpropagation

- 예제

---

## 3. Small VLM과 파운데이션 모델들 소개

VML 유용하긴 하나 비싸다, 개인 컴퓨터나 스마트폰에서 실행되는 모델은 없을까?
-> Small VLM을 사용하자!

1. OpenVLM
2. sVLM
3. SmolVLM
4. Moondream 0.5B
5. Gemini Nano
6. 길럭시 온디바이스 AI

---

## 4. 한국어 sVLM

### 4-1. 언어별 구조적, 형태적 차이에 따른 토큰화 복잡성

#### 언어별 토큰 길이 격차(토큰 정보밀도 차이)

- 언어에 따라 동일한 문장이라도 토큰화 후 길이에 큰 차이를 보임
- 영어 중심 토크나이저
  - 영어는 일부 언어보다 최대 2.5배 토큰 정보 밀도를 보여, 같은 토큰 길이에 더 많은 내용을 담을 수 있음
  - 비영어권 언어는 컨텍스트 활용 효율이 낮고, 토큰 낭비가 발생하는 "구조적" 불이익 존재

#### 토크나이저의 언어 편중 이슈

- 토크나이저의 언어 편중 이슈
  - 주로 빈도가 높은 표현에 대한 설계되어, 사용 빈도가 적거나 형태가 설계 언어와 다른 언어는 비효율적으로 긴 토큰 시퀀스가 생성
- 형태소가 복잡한 언어의 토큰화
  - 핀란드어, 독일어의 경우, 하나의 단어가 매우 길거나 여러 의미를 접합해 표현하므로, 서브워드 단위로 쪼개지는 토큰 수가 크게 증가

### 4-2. 한국어 sVLM 모델

### 4-3. 다른 이미지 파운데이션 모델

#### 이미지 파운데이션 모델

#### 이미지 세그멘테이션 모델

#### 이미지 내 물체 담지 모델

#### 이미지 내 인스턴스 탐지 및 세그멘테이션 모델

#### 비디오 내 인스턴스 탐지 및 세그멘테이션 모델

#### 영상 생성 파운데이션 모델들

- 이미지 생성을 확장시켜서 3D 객체 생성, 텍스트 외에 조건을 입력 받아 이미지 생성 + 영상 생성도 마찬가지인가?
