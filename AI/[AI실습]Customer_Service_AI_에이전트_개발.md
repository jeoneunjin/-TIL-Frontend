# ğŸ“Š Customer Service AI ì—ì´ì „íŠ¸ ê°œë°œ : RAG ê¸°ë°˜ í•™ìŠµ ì •ë¦¬

## ğŸ“š ëª©ì°¨

- ***

---

## 1. í™˜ê²½ ì„¤ì •

### 1-1. ì²­í‚¹/íŒŒì‹±

#### ê°œë… ìš”ì•½

| êµ¬ë¶„                | ê°œë…                                                                                                | ë¹„ìœ                                 |
| ------------------- | --------------------------------------------------------------------------------------------------- | ----------------------------------- |
| **ì²­í‚¹ (Chunking)** | ê¸´ ë¬¸ì„œë¥¼ LLMì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ **ì‘ì€ ë‹¨ìœ„(ì²­í¬)**ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •                                  | ê¸´ ì±…ì„ **ì±•í„°ë³„ë¡œ ë‚˜ëˆ  ì½ê¸°**      |
| **íŒŒì‹± (Parsing)**  | ë³µì¡í•œ ë¬¸ì„œ(PDF, ì›¹í˜ì´ì§€ ë“±)ì—ì„œ LLMì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” **ìˆœìˆ˜ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ê³¼ì •** | ë¬¸ì„œì—ì„œ **ì¤‘ìš”í•œ ë‚´ìš©ë§Œ í•„ê¸°í•˜ê¸°** |

#### ğŸ§  LLMì´ ë¬¸ì„œë¥¼ ì´í•´í•˜ë ¤ë©´ ì™œ ì²­í‚¹(Chunking)ê³¼ íŒŒì‹±(Parsing)ì´ í•„ìš”í• ê¹Œ?

#### 1ï¸âƒ£ ì²­í‚¹ì´ í•„ìš”í•œ ì´ìœ 

- LLMì€ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ì–‘ì´ ì œí•œë˜ì–´ ìˆìŒ
  â†’ ì´ í•œê³„ë¥¼ **ì»¨í…ìŠ¤íŠ¸ ì°½(Context Window)**ì´ë¼ê³  í•¨.
- ê¸´ ë¬¸ì„œë¥¼ ê·¸ëŒ€ë¡œ ë„£ìœ¼ë©´ ì´ˆë°˜ë¶€ë§Œ ì´í•´í•˜ê±°ë‚˜ í›„ë°˜ë¶€ëŠ” ìŠì–´ë²„ë¦¼
- ë”°ë¼ì„œ, ë¬¸ì„œë¥¼ **ì²­í¬(chunk)** ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ìˆœì°¨ì ìœ¼ë¡œ ì´í•´í•˜ê²Œ í•¨

#### 2ï¸âƒ£ íŒŒì‹±ì´ í•„ìš”í•œ ì´ìœ 

- ë¬¸ì„œì—ëŠ” í…ìŠ¤íŠ¸ ì™¸ì—ë„ **í‘œ, ì´ë¯¸ì§€, ë§í¬, ì„œì‹ ë“± ë¹„í…ìŠ¤íŠ¸ ìš”ì†Œ**ê°€ ë§ìŒ
- LLMì€ ì´ëŸ° ë¹„í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì§ì ‘ ì²˜ë¦¬í•˜ê¸° ì–´ë ¤ì›€
- ë”°ë¼ì„œ ë¬¸ì„œë¥¼ **íŒŒì‹±(Pasing)**í•´ì„œ LLMì´ ì½ê¸° ì¢‹ì€ í˜•íƒœ(í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„°)ë¡œ ë³€í™˜í•´ì•¼ í•¨

### 1-2. í† í¬ë‚˜ì´ì§•/ì²­í‚¹

ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë‹¤ë£¨ëŠ” ë‘ ê°€ì§€ í•µì‹¬ ë°©ë²•
â†’ **í† í¬ë‚˜ì´ì§•(Tokenizing)** ê³¼ **ì²­í‚¹(Chunking)**

#### ğŸ§  1ï¸âƒ£ í† í¬ë‚˜ì´ì§• (Tokenizing)

> **ì •ì˜ :**
> í…ìŠ¤íŠ¸ë¥¼ LLMì´ ì´í•´í•˜ëŠ” ê°€ì¥ ì‘ì€ ë‹¨ìœ„ì¸ **í† í°(token)**ìœ¼ë¡œ ìª¼ê°œëŠ” ê³¼ì •

#### âœ… ì£¼ìš” íŠ¹ì§•

- ë‹¨ì–´, êµ¬ë‘ì , ê³µë°± ë“±ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì„¸ë¶„í™”
- `tiktoken` ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ë³„ í† í°í™”ë¥¼ ìˆ˜í–‰
- **ë¬¸ì ìˆ˜ â‰  í† í° ìˆ˜** â†’ ì–¸ì–´ êµ¬ì¡°ë‚˜ ì¸ì½”ë”© ë°©ì‹ì— ë”°ë¼ ë‹¬ë¼ì§
- LLMì€ í† í° ë‹¨ìœ„ë¡œ ì…ë ¥ì„ ì½ê³  ì´í•´í•¨
- ëª¨ë¸ë§ˆë‹¤ ìµœëŒ€ í† í° ìˆ˜(ì»¨í…ìŠ¤íŠ¸ ì°½) ì œí•œì´ ìˆìŒ

#### ğŸ“˜ ì˜ˆì‹œ

> â€œì•ˆë…•í•˜ì„¸ìš”!â€ â†’ ["ì•ˆë…•", "í•˜ì„¸ìš”", "!"]
> í•œê¸€ 5ìë¼ë„, ì‹¤ì œë¡œëŠ” 3~5ê°œ í† í°ìœ¼ë¡œ ìª¼ê°œì§ˆ ìˆ˜ ìˆìŒ

#### ğŸ§© 2ï¸âƒ£ ì²­í‚¹ (Chunking)

> **ì •ì˜ :**
> ê¸´ ë¬¸ì„œë¥¼ ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê´€ ìˆëŠ” **ì²­í¬(Chunk)** ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •

#### âœ… ì£¼ìš” íŠ¹ì§•

- LLMì´ í•œ ë²ˆì— ë‹¤ ì½ì„ ìˆ˜ ì—†ëŠ” ê¸´ ë¬¸ì„œë¥¼ ì—¬ëŸ¬ ì¡°ê°ìœ¼ë¡œ ë¶„ë¦¬
- `RecursiveCharacterTextSplitter` ê°™ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ **ì¤„ë°”ê¿ˆ, ë¬¸ë‹¨, êµ¬ë‘ì  ê¸°ì¤€ìœ¼ë¡œ ì¬ê·€ì  ë¶„í• **

#### âš™ï¸ ì£¼ìš” íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„°        | ì„¤ëª…                                                                                |
| --------------- | ----------------------------------------------------------------------------------- |
| `chunk_size`    | ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜. ë„ˆë¬´ í¬ë©´ ë¶ˆí•„ìš”í•œ ë‚´ìš©ì´ ì„ì´ê³ , ë„ˆë¬´ ì‘ìœ¼ë©´ ì •ë³´ê°€ í©ì–´ì§ |
| `chunk_overlap` | ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜. ë¬¸ë§¥ì´ ëŠê¸°ì§€ ì•Šë„ë¡ ì¼ì • ë¶€ë¶„ì„ ì¤‘ë³µ í¬í•¨ì‹œí‚´              |

#### ğŸ” ì„¤ì •ì— ë”°ë¥¸ ë³€í™”

- chunk_sizeê°€ ì‘ì„ìˆ˜ë¡ â†’ ì²­í¬ ê°œìˆ˜ ë§ì•„ì§, ì„¸ë°€í•œ ë¶„í• 
- chunk_overlapì´ í´ìˆ˜ë¡ â†’ ë¬¸ë§¥ ìœ ì§€ ì˜ë¨, ì¤‘ë³µ ë°ì´í„° ì¦ê°€

> **ğŸ’¡ í•µì‹¬ ì°¨ì´:**
>
> - í† í¬ë‚˜ì´ì§•ì€ LLMì˜ ì–¸ì–´ ì²˜ë¦¬ ë‹¨ìœ„
> - ì²­í‚¹ì€ RAG ì‹œìŠ¤í…œì˜ ì •ë³´ ê²€ìƒ‰ ë‹¨ìœ„

### 1-4. ì½”ë“œ ì˜ˆì‹œ

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter
import tiktoken

# ì˜ˆì‹œ í…ìŠ¤íŠ¸
text = """
AI ì˜¨ë¼ì¸ ì„œì ì…ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ì†Œì¤‘í•œ ë¬¸ì˜ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.
ë°°ì†¡ ì •ì±…ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ì¼ë°˜ ë„ì„œì˜ ê²½ìš° ì˜¤í›„ 3ì‹œ ì´ì „ ì£¼ë¬¸ ì‹œ ë‹¹ì¼ ë°œì†¡ë©ë‹ˆë‹¤.
ì£¼ë§ ë° ê³µíœ´ì¼ì€ ë°°ì†¡ì´ ì–´ë µìŠµë‹ˆë‹¤.
ì œì£¼ ë° ë„ì„œ ì‚°ê°„ ì§€ì—­ì€ ì¶”ê°€ ë°°ì†¡ë¹„ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì£¼ë¬¸ ë²ˆí˜¸ order-123ì˜ ë°°ì†¡ ìƒíƒœë¥¼ ì¡°íšŒí•˜ì‹œë ¤ë©´ ë§ˆì´í˜ì´ì§€ì—ì„œ í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
"""

# 1. í† í¬ë‚˜ì´ì§• (tiktoken ì‚¬ìš©)
# ëª¨ë¸ì— ë”°ë¼ ì¸ì½”ë”© ë°©ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” 'cl100k_base'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
encoding = tiktoken.get_encoding('cl100k_base')
tokens = encoding.encode(text)

print("--- í† í¬ë‚˜ì´ì§• ê²°ê³¼ ---")
print(f"ì›ë¬¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)} ë¬¸ì")
print(f"í† í° ìˆ˜: {len(tokens)} í† í°")
print(f"í† í° ì˜ˆì‹œ: {tokens[:10]}...") # ì²« 10ê°œ í† í° ì˜ˆì‹œ
print("-" * 20)


# 2. ì²­í‚¹ (RecursiveCharacterTextSplitter ì‚¬ìš©)

# ë‹¤ì–‘í•œ chunk_sizeì™€ chunk_overlapìœ¼ë¡œ ë¹„êµ
chunking_configs = [
    {"chunk_size": 100, "chunk_overlap": 0},
    {"chunk_size": 100, "chunk_overlap": 20},
    {"chunk_size": 50, "chunk_overlap": 0},
    {"chunk_size": 50, "chunk_overlap": 10},
]

print("\n--- ì²­í‚¹ ê²°ê³¼ ë¹„êµ ---")

for config in chunking_configs:
    chunk_size = config["chunk_size"]
    chunk_overlap = config["chunk_overlap"]

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len, # ê¸¸ì´ë¥¼ ë¬¸ìë¡œ ê³„ì‚°
        is_separator_regex=False,
    )

    chunks = text_splitter.create_documents([text])

    print(f"\n[Chunk Size: {chunk_size}, Chunk Overlap: {chunk_overlap}]")
    print(f"ìƒì„±ëœ ì²­í¬ ê°œìˆ˜: {len(chunks)}")
    for i, chunk in enumerate(chunks):
        print(f"  ì²­í¬ {i+1} (ê¸¸ì´: {len(chunk.page_content)}):")
        print(f"  '{chunk.page_content[:50]}...'") # ê° ì²­í¬ì˜ ì•ë¶€ë¶„ë§Œ ì¶œë ¥

print("-" * 20)
```

---

## 2. LangChain

### 2-1. ğŸ§© LangChain ê°œìš”

> LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•´ ì±—ë´‡, QA ì‹œìŠ¤í…œ ë“± AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì„.  
> í”„ë¡œê·¸ë˜ë° ê²½í—˜ ì—†ì–´ë„ í…œí”Œë¦¿ê³¼ ë„êµ¬ë¥¼ í†µí•´ ë¹ ë¥´ê²Œ ê°œë°œ ë° ë°°í¬ ê°€ëŠ¥í•¨.  
> ë³µì¡í•œ ê°œë°œ ê³¼ì • ë‹¨ìˆœí™”í•˜ì—¬ AI ì•± ê°œë°œ ì§„ì… ì¥ë²½ ë‚®ì¶°ì¤Œ.

#### ğŸ—ï¸ LangChain êµ¬ì„±ìš”ì†Œ

#### ğŸ”¹ 1. LangChain Library

LangChain ê¸°ëŠ¥ ëª¨ì•„ë‘” íŒ¨í‚¤ì§€ ëª¨ìŒì„.

- **`langchain-core`**: LangChain ê¸°ë³¸ ë¬¸ë²• ì œê³µ
- **Integrated Packages**: ì™¸ë¶€ ë„êµ¬ì™€ LangChain ì—°ê²° ì‰½ê²Œ í•¨
  > ì˜ˆ: `langchain-upstage`, `langchain-chroma`
- **`langchain`**: ì²´ì¸, ì—ì´ì „íŠ¸, ê²€ìƒ‰ ì „ëµ ë“± ì• í”Œë¦¬ì¼€ì´ì…˜ ë‘ë‡Œ ì—­í• 

#### ğŸ”¹ 2. LangChain Templates

ì‘ì—…ë³„ í…œí”Œë¦¿ ì œê³µí•¨.  
ë¹ ë¥´ê²Œ ì„¤ì •í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ ë„ì™€ì¤Œ.

#### ğŸ”¹ 3. LangServe

LangChainìœ¼ë¡œ ë§Œë“  ì• í”Œë¦¬ì¼€ì´ì…˜ì„ **REST API í˜•íƒœë¡œ ë°°í¬**í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„êµ¬ì„.

#### ğŸ”¹ 4. LangSmith

ì• í”Œë¦¬ì¼€ì´ì…˜ **ë””ë²„ê·¸, í…ŒìŠ¤íŠ¸, ëª¨ë‹ˆí„°ë§** ì§€ì›í•˜ëŠ” í”Œë«í¼ì„.

#### ğŸ”¹ 5. LangGraph

LLMì˜ ì—¬ëŸ¬ ìƒíƒœ ê´€ë¦¬í•˜ë©´ì„œ **Agent êµ¬ì¡°í™”** ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì„.

---

### 2-2.ğŸ’¡ ì½”ë“œ êµ¬ì„± ìš”ì•½

#### 1ï¸âƒ£ ì„ í˜¸í•˜ëŠ” LLM ì •ì˜

- `langchain_upstage`ì—ì„œ `ChatUpstage` ê°€ì ¸ì˜´
- `ChatUpstage()` ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„ `llm` ë³€ìˆ˜ì— ì €ì¥

#### 2ï¸âƒ£ ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì •ì˜

- `langchain_core.prompts`ì˜ `ChatPromptTemplate` ì‚¬ìš©
- `from_messages()`ë¡œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì˜ˆì œ, ì‚¬ìš©ì ì…ë ¥ ë“± í¬í•¨í•œ í…œí”Œë¦¿ ìƒì„±

#### 3ï¸âƒ£ ì¶œë ¥ íŒŒì„œ ì •ì˜

- `langchain_core.output_parsers`ì˜ `StrOutputParser` ì‚¬ìš©
- ì¶œë ¥ í˜•ì‹ ì •ì˜
- ë” ìì„¸í•œ ë‚´ìš©ì€ **LangChain Guide ì°¸ê³ **

#### 4ï¸âƒ£ ì²´ì¸ ì •ì˜

- `rag_with_history_prompt`, `llm`, `StrOutputParser()`ë¥¼ íŒŒì´í”„(`|`) ì—°ì‚°ìë¡œ ì—°ê²°í•´ ì²´ì¸ êµ¬ì„±

#### 5ï¸âƒ£ ì²´ì¸ í˜¸ì¶œ

- `chain.invoke({})`ë¡œ ì‹¤í–‰
- ê²°ê³¼ ì¶œë ¥

### 2-3. ì½”ë“œ

```python
# LLM Chain êµ¬ì„±í•˜ëŠ” ë²•
# 1. llm ì •ì˜, 2. prompt ì •ì˜, 3. chain ì •ì˜, 4. chain í˜¸ì¶œ

# 1. define your favorite llm, solar
from langchain_upstage import ChatUpstage

llm = ChatUpstage()

# 2. define chat prompt
from langchain_core.prompts import ChatPromptTemplate  # 'ëŒ€í™”' í˜•íƒœë¡œ prompt template ìƒì„±

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "ëª¨ë“  ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ê³µì†í•œ ë§íˆ¬ë¡œ í•´ì£¼ì„¸ìš”."),

        # few-shot prompting
        ("human", "ì§€êµ¬ì—ì„œ ê°€ì¥ í° ë°”ë‹¤ëŠ” ì–´ë””ì¸ê°€ìš”?"),  # human request
        ("ai", "ë„¤, íƒœí‰ì–‘ì´ ê°€ì¥ í° ë°”ë‹¤ì…ë‹ˆë‹¤."),         # LLM response
        ("human", "ê·¸ëŸ¼, ê°€ì¥ ê¸´ ê°•ì€ ì–´ë””ì¸ê°€ìš”?"),
        ("ai", "ê°€ì¥ ê¸´ ê°•ì€ ë‚˜ì¼ê°•ì…ë‹ˆë‹¤."),

        # User Query
        ("human", "ê·¸ë ‡ë‹¤ë©´, ê°€ì¥ ë†’ì€ ì‚°ì€ ì–´ë””ì¸ê°€ìš”?"),
    ]
)

# 3. define chain
from langchain_core.output_parsers import StrOutputParser  # ë¬¸ìì—´(text, string)ë§Œ ë‚˜ì˜¤ê²Œ í•˜ëŠ” ì¶œë ¥ íŒŒì„œ

# chain = prompt | llm  # without output parser

chain = prompt | llm | StrOutputParser()  # with output parser

# 4. invoke the chain
c_result = chain.invoke({})
print(c_result)
```

---

## 3. RAG & Tool
