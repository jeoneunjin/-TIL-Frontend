# ğŸ“Š íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ í•™ìŠµ ë‚´ìš© ìš”ì•½

## ğŸ¯ í•™ìŠµ ëª©í‘œ

- ë°ì´í„°ì˜ êµ¬ì¡°ì™€ íŠ¹ì„±ì„ ì´í•´í•˜ê³ , ì‹œê°í™” ë° í†µê³„ì  ìš”ì•½ì„ í†µí•´ íŒ¨í„´ì„ íŒŒì•…
- **ì´ìƒì¹˜Â·ê²°ì¸¡ì¹˜Â·ìƒê´€ê´€ê³„** ë“±ì„ íƒìƒ‰í•˜ì—¬ ëª¨ë¸ë§ ì „ ë°ì´í„° í’ˆì§ˆ ê°œì„ 
- ì „ì²˜ë¦¬ë¶€í„° í‰ê°€ê¹Œì§€ ì „ì²´ **íŒŒì´í”„ë¼ì¸**ì„ ì²´ê³„ì ìœ¼ë¡œ êµ¬ì¶•

---

## ğŸ§¾ í‚¤ì›Œë“œ

- EDA(Exploratory Data Analysis)
- ìƒê´€ê´€ê³„(Correlation)
- ì´ìƒì¹˜(Outlier)
- ê²°ì¸¡ì¹˜(Missing Value)
- íŒŒì´í”„ë¼ì¸(Pipeline)
- í‘œì¤€í™”(Standardization)
- êµì°¨ ê²€ì¦(Cross Validation)

---

## ğŸ“š ëª©ì°¨

1. [íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)](#1-íƒìƒ‰ì -ë°ì´í„°-ë¶„ì„eda-exploratory-data-analysis)
2. [ìƒê´€ê´€ê³„ ë¶„ì„](#2-ìƒê´€ê´€ê³„-ë¶„ì„correlation-analysis)
3. [ì´ìƒì¹˜ ì²˜ë¦¬](#3-ì´ìƒì¹˜outlier-ì²˜ë¦¬)
4. [ê²°ì¸¡ì¹˜ ì²˜ë¦¬](#4-ê²°ì¸¡ì¹˜missing-value)
5. [íŒŒì´í”„ë¼ì¸](#5-íŒŒì´í”„ë¼ì¸pipeline)

---

## 1. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA, Exploratory Data Analysis)

> ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ íŒ¨í„´ì„ ì´í•´í•˜ê¸° ìœ„í•´ **ì‹œê°í™”ì™€ í†µê³„ì  ìš”ì•½ì„ í†µí•´ ë°ì´í„°ë¥¼ íƒìƒ‰**í•˜ëŠ” ê³¼ì •

- ëª¨ë¸ë§ ì „ ë‹¨ê³„ì—ì„œ ë°ì´í„°ì˜ í’ˆì§ˆê³¼ ë¬¸ì œì ì„ í™•ì¸
- **êµ¬ì¡°Â·í¬ê¸°Â·ê²°ì¸¡ì¹˜Â·ì´ìƒì¹˜Â·ë¶„í¬ íŠ¹ì„±** ë“±ì„ íŒŒì•…í•˜ì—¬ ì „ì²˜ë¦¬ ë°©í–¥ì„ ì„¤ì •

### 1-1. Quality íŠ¹ì„± ë¶„ì„

#### ë‹¨ì¼ íŠ¹ì„± ë¶„ì„

| ë¶„ì„ í•­ëª©   | ì½”ë“œ ì˜ˆì‹œ                           | ì„¤ëª…                   |
| ----------- | ----------------------------------- | ---------------------- |
| íŠ¹ì„± ì¶”ì¶œ   | `pd.Series(car_dataframe['price'])` | ê°œë³„ ë³€ìˆ˜(Series) ì¶”ì¶œ |
| í´ë˜ìŠ¤ ê°œìˆ˜ | `.nunique()`                        | ê³ ìœ ê°’ì˜ ê°œìˆ˜ í™•ì¸     |
| í´ë˜ìŠ¤ ë¶„í¬ | `.value_counts().sort_index()`      | ê° ê°’ì˜ ë¹ˆë„ ì •ë ¬ í™•ì¸ |

#### ë‹¤ì¤‘ íŠ¹ì„± ë¶„ì„

- ì—¬ëŸ¬ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ `describe()`, `corr()`, `pairplot()` ë“±ì„ í™œìš©
- ì˜ˆ: `sns.pairplot(car_dataframe)` â†’ ë³€ìˆ˜ ê°„ ë¶„í¬ ë° ìƒê´€ ê´€ê³„ ì‹œê°í™”

---

## 2. ìƒê´€ê´€ê³„ ë¶„ì„(Correlation Analysis)

> ë‘ íŠ¹ì„± ê°„ì˜ **ì„ í˜• ê´€ê³„**ë¥¼ ìˆ˜ì¹˜ì™€ ì‹œê°í™”ë¡œ íŒŒì•…

- **íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ê´€ê³„**ë¥¼ íŒŒì•…í•˜ì—¬ ëª¨ë¸ë§ì— ìœ ì˜ë¯¸í•œ íŠ¹ì„± ì„ íƒ
- **ìƒê´€ê´€ê³„ â‰  ì¸ê³¼ê´€ê³„**
  - ìƒê´€ê´€ê³„ëŠ” ë‹¨ìˆœí•œ ìˆ˜í•™ì  ê´€ê³„ì´ë©°, ì¸ê³¼ê´€ê³„ë¥¼ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ
  - âš ï¸ **í˜¼ì¬ë³€ìˆ˜(confounding variable)** ì¡´ì¬ ê°€ëŠ¥

### 2-1. í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜(Pearson Correlation Coefficient)

| êµ¬ë¶„      | ì„¤ëª…                   |
| --------- | ---------------------- |
| ê°’ì˜ ë²”ìœ„ | `-1 ~ 1`               |
| +1 ê·¼ì²˜   | ê°•í•œ **ì–‘ì˜ ì„ í˜•ê´€ê³„** |
| -1 ê·¼ì²˜   | ê°•í•œ **ìŒì˜ ì„ í˜•ê´€ê³„** |
| 0 ê·¼ì²˜    | ê±°ì˜ **ë¬´ìƒê´€ ê´€ê³„**   |

### 2-2. ìƒê´€ê³„ìˆ˜ í–‰ë ¬

> ì—¬ëŸ¬ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ ì •ë„ë¥¼ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìƒê´€ ê³„ìˆ˜ë¥¼ **í–‰ë ¬ í˜•íƒœ**ë¡œ ì‹œê°í™”í•œ ê²ƒ

- ì£¼ëŒ€ê°ì„ (diagonal): ìê¸° ìì‹ ê³¼ì˜ ìƒê´€ â†’ í•­ìƒ 1
- ì£¼ëŒ€ê°ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ í•œìª½ì˜ ë°ì´í„°ë§Œ í•„ìš”í•˜ë‹¤(ëŒ€ì¹­)
- ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ ì§€ìš°ê¸° ìœ„í•´ **ìƒì‚¼ê°í–‰ë ¬(mask)**ì„ ì´ìš©í•¨

---

## 3. ì´ìƒì¹˜(Outlier) ì²˜ë¦¬

> ë‹¤ë¥¸ ë°ì´í„°ì™€ í˜„ì €íˆ ë‹¤ë¥¸ ê°’ (ì˜¤ë¥˜ì´ê±°ë‚˜ ê·¹ë‹¨ì ì¸ ì‹¤ì œê°’)
> ì¸¡ì • ì˜¤ë¥˜, ì…ë ¥ ì‹¤ìˆ˜ì´ê±°ë‚˜ ì‹¤ì œë¡œ ì¸¡ì •ëœ ê°’ì´ì§€ë§Œ ê·¹ë‹¨ì ì¸ ê²½ìš°ë¥¼ ë§í•¨

- ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ë° ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì²˜ë¦¬ í•„ìš”
- í•™ìŠµ ë°ì´í„°ì— ê·¹ë‹¨ê°’ ì¶”ê°€ ì‹¤ìŠµì„ í†µí•´ ì´ìƒì¹˜ íƒì§€ ê¸°ë²•ì„ ìµí˜

### 3-1. ì‚¬ë¶„ìœ„ìˆ˜ ë²”ìœ„(IQR, Interquartile Range)

> 1ì‚¬ë¶„ìœ„ìˆ˜ì™€ 3ì‚¬ë¶„ìœ„ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ë°ì´í„°ë¥¼ ì´ìƒì¹˜ë¡œ íŒë‹¨í•˜ëŠ” ë°©ë²•
> `IQR = Q3 = Q1`

- ì´ìƒì¹˜ íŒë‹¨ ê¸°ì¤€ :

  - Q1 - 1.5 \* IQR ë¯¸ë§Œ
  - Q3 + 1.5 \* IQR ì´ˆê³¼

- boxplotë¥¼ ì´ìš©í•˜ì—¬ ì´ìƒì¹˜ í™•ì¸
  ![Boxplot ì„¤ëª…](./img/ai/boxplot_explanation.png)
  | êµ¬ì„± ìš”ì†Œ | ì˜ë¯¸ |
  | ----- | --------- |
  | ë°•ìŠ¤ í•˜ë‹¨ | Q1 |
  | ë°•ìŠ¤ ì¤‘ì•™ | Q2 (ì¤‘ì•™ê°’) |
  | ë°•ìŠ¤ ìƒë‹¨ | Q3 |
  | ë°•ìŠ¤ ë†’ì´ | IQR |
  | ì„  | 1.5 Ã— IQR |
  | ì  | ì´ìƒì¹˜ |

### 3-2. Z-Score

> ë°ì´í„°ê°€ í‰ê· ìœ¼ë¡œë³´í„° **í‘œì¤€í¸ì°¨ì˜ ëª‡ ë°°ë§Œí¼ ë–¨ì–´ì ¸ ìˆëŠ”ì§€** ì¸¡ì •

- Z-Scoreì˜ ì ˆëŒ“ê°’ì´ 3 ì´ˆê³¼ â†’ ì´ìƒì¹˜ë¡œ ê°„ì£¼

```python
from scipy import stats
z = np.abs(stats.zscore(df['price']))
outliers = df[z > 3]
```

---

## 4. ê²°ì¸¡ì¹˜(Missing Value)

> ë°ì´í„°ê°€ ëˆ„ë½ëœ ê²½ìš° (ê¸°ë¡ ì˜¤ë¥˜, ìˆ˜ì§‘ ì‹¤íŒ¨ ë“±)

- ê²°ì¸¡ì¹˜ê°€ ë§ìœ¼ë©´ ëª¨ë¸ í•™ìŠµì— ì‹¬ê°í•œ ì˜í–¥ì„ ì¤Œ â†’ ì ì ˆí•œ ëŒ€ì²´ í•„ìš”

### 4-1. ê²°ì¸¡ì¹˜ ëŒ€ì²´

| ë°ì´í„° ìœ í˜• | ì²˜ë¦¬ ë°©ë²•                          | ì˜ˆì‹œ                                          |
| ----------- | ---------------------------------- | --------------------------------------------- |
| ì—°ì†í˜•      | í‰ê· (`mean()`), ì¤‘ì•™ê°’(`median()`) | `df['age'].fillna(df['age'].mean())`          |
| ë²”ì£¼í˜•      | ìµœë¹ˆê°’(`mode()[0]`)                | `df['gender'].fillna(df['gender'].mode()[0])` |

### 4-2. SimpleImputer

#### 3. SimpleImputer

> `sklearn` ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” ë©”ì„œë“œë¡œ ê²°ì¸¡ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ëŒ€ì²´í•´ì¤Œ

```python
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='median')
X = imputer.fit_transform(df)
```

---

## 5. íŒŒì´í”„ë¼ì¸(Pipeline)

> ë°ì´í„° **ì „ì²˜ë¦¬ â†’ í•™ìŠµ â†’ í‰ê°€**ì˜ ì „ì²´ ê³¼ì •ì„ ì¼ê´€ë˜ê²Œ ê´€ë¦¬í•˜ëŠ” íë¦„

- `sklearn` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ íŒŒì´í”„ë¼ì¸ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŒ

## 5-1. ë°ì´í„° ë¶„í• (Train/Test Split)

> í•™ìŠµìš©ê³¼ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì–´ **ì¼ë°˜í™” ì„±ëŠ¥ í‰ê°€**

```python
# í‰ê°€ìš©(Test) ë°ì´í„°ì˜ ë¹„ìœ¨ì„ 40%ë¡œ ì„¤ì •í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(
    X,y,
    test_size=0.4,      # ì „ì²´ ë°ì´í„° ì¤‘ 40%ë¥¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ
    random_state=42,    # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚œìˆ˜ ì‹œë“œ ê³ ì •
    stratify=y          # í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ë¶„í• 
)
```

> `stratify=y`: í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë„ë¡ ë¶„í• 
> ì´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ í•œìª½ ë°ì´í„°ì…‹ì— íŠ¹ì • í´ë˜ìŠ¤ë§Œ ëª°ë¦´ ìˆ˜ ìˆìŒ

## 5-2. ë°ì´í„° í‘œì¤€í™”(Standardization)

> í‰ê· ì„ 0, í‘œì¤€í¸ì°¨ë¥¼ 1ë¡œ ë§ì¶”ì–´ í•™ìŠµ ì•ˆì •í™”

```python
# StandardScalerë¥¼ ì´ìš”í•˜ì—¬ ë°ì´í„° í‘œì¤€í™”
scaler = StandardScaler()
scaler.fit(X_train)

# Trainê³¼ Test ë°ì´í„° ëª¨ë‘ ë³€í™˜
X_train_norm = scaler.transform(X_trian)
X_test_norm = scaler.transform(X_test)

# X_train_norm = scaler.fit_transform(X_train)

```

## 5-3. ëª¨ë¸ í•™ìŠµ(Training)

> `LogisticRegression`ì€ í™•ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸

```python
# LogisticRegression ëª¨ë¸ ì„ ì–¸
from sklearn.linear_model import LogisticRegression
model =  LogisticRegression(max_iter=1000)

# ëª¨ë¸ í•™ìŠµ
model.fit(X_train_norm, y_train)

# ëª¨ë¸ ì˜ˆì¸¡
y_pred = model.predict(X_test_norm)
print(y_pred)
print(y_test)
```

## 5-4. ëª¨ë¸ í‰ê°€(Evaluation)

- ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ í‰ê°€ ì§„í–‰, í˜¼ë™ í–‰ë ¬, ë¶„ë¥˜ ë¦¬í¬íŠ¸, ROC-AUC ê³¡ì„ ì„ ì´ìš©í•˜ì—¬ í‰ê°€
  | í‰ê°€ ì§€í‘œ | ì˜ë¯¸ |
  | -------------------- | ------------------------ |
  | Accuracy | ì „ì²´ ì˜ˆì¸¡ ì¤‘ ë§ì¶˜ ë¹„ìœ¨ |
  | Precision | ì–‘ì„± ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ ì–‘ì„± ë¹„ìœ¨ |
  | Recall (Sensitivity) | ì‹¤ì œ ì–‘ì„± ì¤‘ ë§ì¶˜ ë¹„ìœ¨ |
  | F1-score | Precisionê³¼ Recallì˜ ì¡°í™” í‰ê·  |

### 1ï¸âƒ£ í˜¼ë™ í–‰ë ¬(Confusion Matrix)

> ì •ë°€ë„, ì¬í˜„ìœ¨ì„ ê³„ì‚°í•˜ê¸° ìœ„í•œ í–‰ë ¬

| êµ¬ë¶„ | ê¸ì •      | ë¶€ì •                      |                         |
| ---- | --------- | ------------------------- | ----------------------- |
| ê¸ì • | TP        | FN                        | Sensitivity ë˜ëŠ” Recall |
| ë¶€ì • | FP        | TN                        | Specificity             |
|      | Precision | Negative Predictive Value | Accuracy                |

- í˜¼ë™ í–‰ë ¬ ê³„ì‚°

```python
from sklearn.metrics import confusion_matrix

CM = confusion_matrix(y_test, y_pred)
print(CM)
```

### 2ï¸âƒ£ ë¶„ë¥˜ ë¦¬í¬íŠ¸(Classification Report)

> ì •ë°€ë„, ì¬í˜„ìœ¨, F1-score ë“± ì—¬ëŸ¬ ì§€í‘œë¥¼ ìš”ì•½í•´ì„œ ë³´ì—¬ì£¼ëŠ” í‘œ

```python
from sklearn.metrics import classification_report
print(classificatinon_report(y_test, y_pred))
```

### 3ï¸âƒ£ ROC-AUC

> **TPR(ë¯¼ê°ë„)**ì™€ **FPR(ì˜¤íƒìœ¨)** ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê³¡ì„ 

- **AUC**ëŠ” ë©´ì ê°’ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìš°ìˆ˜)
- 0.5ëŠ” ë¬´ì‘ìœ„ ë¶„ë¥˜ê¸° ìˆ˜ì¤€ì„ ì˜ë¯¸

```python
from sklearn.metrics import roc_auc_score, roc_curve
roc_auc_score(y_test, y_pred)
```

### 4ï¸âƒ£ êµì°¨ ê²€ì¦(Cross Validation)

> ì—¬ëŸ¬ í´ë“œë¡œ ë‚˜ëˆ„ì–´ ë°˜ë³µì ìœ¼ë¡œ í•™ìŠµ ë° í‰ê°€
> ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë° ì‚¬ìš©

```python
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, X_train_norm, y_train, cv=5)
print(scores.mean())
```

---

## âœ… ì •ë¦¬ ìš”ì•½

| êµ¬ë¶„       | ì£¼ìš” ëª©ì            | ëŒ€í‘œ ê¸°ë²•                                        |
| ---------- | ------------------- | ------------------------------------------------ |
| íƒìƒ‰(EDA)  | ë°ì´í„° êµ¬ì¡° ì´í•´    | `describe()`, `pairplot()`                       |
| ìƒê´€ê´€ê³„   | ë³€ìˆ˜ ê°„ ê´€ê³„ í™•ì¸   | `corr()`, `heatmap()`                            |
| ì´ìƒì¹˜     | ê·¹ë‹¨ê°’ íƒì§€ ë° ì²˜ë¦¬ | `IQR`, `Z-Score`, `boxplot()`                    |
| ê²°ì¸¡ì¹˜     | ëˆ„ë½ê°’ ë³´ì •         | `mean`, `median`, `SimpleImputer`                |
| íŒŒì´í”„ë¼ì¸ | ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬  | `train_test_split`, `StandardScaler`, `Pipeline` |
