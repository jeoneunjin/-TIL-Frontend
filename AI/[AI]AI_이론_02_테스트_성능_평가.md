# 🤖 AI & 기계 학습 기초 (2)

## 📚 목차

1. [테스트 성능 평가](#1-테스트-성능-평가)
2. [검증셋 접근](#2-검증셋-접근)
   - [검증셋(Validation Set) 방법](#2-1-검증셋validation-set-방법)
3. [K-겹 교차검증](#3-k-겹-교차검증)
   - [K-겹 교차검증 개요](#3-1-k-겹-교차검증)
   - [K-겹 교차검증 오류 계산](#3-2-k-겹-교차검증-오류-계산)
   - [LOOCV (Leave-One-Out)](#3-3-leave-one-out-교차검증)
   - [10-겹 vs LOOCV 비교](#3-4-k-겹-교차검증-비교)

---

## 1. 테스트 성능 평가

### 🔍 훈련 오류 vs 테스트 오류

| 항목           | 설명                                                            |
| -------------- | --------------------------------------------------------------- |
| 🧪 훈련 오류   | 모델이 학습된 **같은 데이터**로 평가한 오류                     |
| 📊 테스트 오류 | **보지 않은 새로운 데이터**(테스트셋)에서 평가한 평균 예측 오류 |

- 일반적으로 **훈련 오류는 테스트 오류를 과소평가**함  
  → 즉, 실제 성능보다 잘 나올 수 있음

### ❗ 왜 중요한가?

> **모델 일반화 성능**은 테스트 오류로 판단해야 하며,  
> 훈련 오류는 이에 대한 잘못된 낙관적 추정이 될 수 있음.

---

## 2. 검증셋 접근

### 2-1. 검증셋(Validation Set) 방법

- 데이터를 무작위로 **훈련셋**과 **검증셋**으로 분할
- 훈련셋으로 모델 학습 → 검증셋으로 성능 평가(MSE, 오분류율 등)

#### 📌 절차

1. 데이터 셔플링 → 훈련/검증으로 분할
2. 훈련셋으로 학습
3. 검증셋으로 테스트 오류 추정

> 📌 일반적으로 70:30 또는 80:20으로 나누지만, 반드시 절반일 필요는 없음

#### ⚠️ 단점

| 문제           | 설명                                                                |
| -------------- | ------------------------------------------------------------------- |
| 분산 큼        | 데이터 분할에 따라 결과가 많이 달라질 수 있음                       |
| 데이터 낭비    | 전체 데이터를 활용하지 못함 (일부만 훈련에 사용됨)                  |
| 과대 추정 경향 | 훈련 데이터가 줄어들어 모델이 충분히 학습되지 않음 → 오류 과대 추정 |

---

## 3. K-겹 교차검증

### 3-1. K-겹 교차검증

- 데이터를 **K개 부분집합(fold)**으로 나눈 뒤,
- 각 fold가 **한 번씩 검증셋이 되고**, 나머지 K-1개는 훈련셋이 됨
- K번 반복 → **평균 오류**를 계산

#### 💡 예: 5-겹 교차검증

- 총 데이터 100개 → 각 fold에 20개씩
- 5번 학습-평가 반복 → 5개의 오류 평균

---

### 3-2. K-겹 교차검증 오류 계산

- 각 fold에서의 **검증 오류(MSE, 오분류율 등)**를 평균하여 최종 오류 추정

> ✅ 데이터 낭비가 없음 (모든 샘플이 최소 한 번은 검증셋이 됨)

---

### 3-3. Leave-One-Out 교차검증 (LOOCV)

- K = n (데이터 수)
- 각 반복마다 **하나의 샘플**을 검증셋으로, 나머지를 훈련셋으로 사용
- 총 n번 반복 → 평균 오류 계산

| 항목   | 내용                          |
| ------ | ----------------------------- |
| 훈련셋 | n-1개 샘플                    |
| 검증셋 | 1개 샘플                      |
| 장점   | 데이터 최대한 활용, 편향 적음 |
| 단점   | 계산 비용 큼, 분산 큼         |

---

### 3-4. K-겹 교차검증 비교

| 항목           | LOOCV   | K-겹 (ex. K=10)                 |
| -------------- | ------- | ------------------------------- |
| 반복 횟수      | n회     | K회                             |
| 검증셋 크기    | 1       | n/K                             |
| 편향(Bias)     | 낮음    | 약간 높음 (적절한 K 선택 시 OK) |
| 분산(Variance) | 높음    | 낮음                            |
| 계산 비용      | 매우 큼 | 상대적으로 적음                 |

#### ✅ 결론

- 대부분의 경우 **10-겹 교차검증이면 충분**
- LOOCV는 **데이터가 매우 적을 때** 또는 **이론적 분석 시** 사용

---

## 💡 추가 팁: 데이터 분할 전략

| 전략          | 특징                                   | 사용 시기                 |
| ------------- | -------------------------------------- | ------------------------- |
| Hold-Out      | 한 번만 분할 (훈련 vs 검증)            | 빠르게 성능 확인할 때     |
| K-겹 교차검증 | K번 분할/평가 → 평균                   | 일반적인 모델 평가에 적합 |
| LOOCV         | 가장 극단적인 형태, 데이터 최대한 활용 | 데이터 수가 매우 적을 때  |

---
