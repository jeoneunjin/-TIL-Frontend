# 🤖 딥러닝 및 이미지 모델(1)

## 📚 목차

- [1. CNN 🖼️](#1-cnn-🖼️)
- [2. CNN 기반 모델 변천사 🔄](#2-cnn-기반-모델-변천사-🔄)
- [3. CNN의 한계 ⚠️](#3-cnn의-한계-⚠️)
- [4. 시퀀스 데이터 처리 : RNN 🔁](#4-시퀀스-데이터-처리--rnn-🔁)
- [5. 긴거리 의존성 : 어텐션/ViT 🎯](#5-긴거리-의존성--어텐션vit-🎯)

---

## 1. CNN

### 1-1. CNN 모델

### 합성곱 레이어(Convolution Layer)

- 입력 이미지를 필터와 연산하여 특징 맵(feature map)을 뽑아내는 모듈
- 1차원 구조로 변환하는 FCN과 달리 3차원 구조를 그대로 보존하면서 연산

#### Filter

> ! 차원을 반드시 Filter는 항상 입력의 깊이/채널 축과 동일한 차원이어야 함 !

- Filter 개수 = 출력 깊이

- 출력 해상도 = 입력 해상도 - 필터 해상도 + 1
  ? 만약 입출력 해상도를 유지하고 싶으면 ?
  -> 출력값 중 정의되지 않은 경우, 0 혹은 가장 가까운 출력값으로 대체(패딩)

* 바이어스도 추가

---

### 1-2. CNN 모델 구조

#### 중첩

선형 layer로 중첩한 구조는 하나의 레이어에 준한다. -> 별다른 결과를 만들진 못함
=> 비선형 layer의 중첩 필요

#### 필터의 의미

- 필터 시각화
  학습된 필터 시각화를 통해 각 모델(구조)가 학습한 정보를 이해 가능

#### 수용 영역

#### 풀링

#### 스트라이드 합성곱 - 풀링 한계 개선

- 일반 합성곱 vs 스트라이드 합성곱
  - 일반 합성곱 : 필터를 1칸씩 이동하면서 연산 수행
  - 스트라이드 합성곱 : 필터를 스트라이드 값만큼(S칸) 이동한 후 출력 연산
- 효과 :
  - 풀링은 학습 상수가 없지만 스트라이드는 커널을 동시에 학습
  - 해상도 저하로 인한 정보 손실이 적고, 풀링 + 합성곱을 하나의 레이어로 대체함
  - 고도화된 CNN에서는 스트라이드 합성곱을 풀링 대신 활용되는 경향

---

## 2. CNN 기반 모델 변천사

### 2-1. AlexNet(2012~)

> 5개의 합성곱 계층과 3개의 완전연결 계층으로 구성된 8계층 CNN 모델

- 모델 구조 특징
  - 5개의 합성곱 레이어 + 맥스 풀링 + 3개 연결층 레이어 + ReLU 비선형 활성화 => 8-레이어
- 입출력
  - 입력 : 이미지 / 3 x 277 x 277
  - 출력 : 레이블 / 1 x 1024 벡터

---

### 2-2. VGGNet(2014~)

> 5개의 합성곱 불록 + 맥스 풀링 구조

- 모델 구조 특징
  - 5개의 합성곱 레이어(각 블록당 합성곱 - ReLU 구조가 반복)
  - **각 블록당 맥스 풀링**
  - 3개 연결층 레이어
  - ReLU 비선형 활성화
  - **총 16개의 합성곱/연결층 레이어**
  - **최종 소프트맥스 수행**
- 입출력
  - 입력 : 이미지 / 3 x **244 x 244**
  - 출력 : 레이블 / 1 x 1024 벡터

#### AlexNet과의 비교

- 연산량 비교
  - AlexNet에서는 레이어별 연산량 차이가 매우 큼
  - VGG는 해상도를 줄일 때 마다 채널을 늘려 레이어별 연산량 차이를 줄임(분산하여 연산 처리)
  - AlexNet(0.7GFLOPs) vs VGG-16(13.6GFLOPs) 약 19.4배
- 메모리 비교
  - AlexNet(1.9MB) vs VGG-16(48.6MB) 약 25배
- 모델 상수 비교
  - AlexNet(61M) vs VGG-16(148M) 약 2배

#### 모델 특징

- 단순함 + 깊이의 강력한 성능을 보임
- 단순 설계로 모델 해석에 이상적
- 특징 추출기, 전이학습에 강력한 베이스라인(파라미터가 많고 연산량 요구가 매우 큼)

---

### 2-3. ResNet

> 합성곱 블록(VGG 유사)과 잔차(Residual) 블록
> CNN 기반 구조 중 가장 활발하게 활용

- 모델 구조 특징 :
  - 합성곱 블록과 잔차 블록
  - 잔차 블록은 블록입력을 그대로 출력에 더해주는 지름길 연결이 특징
  - Inception 모델에서 차원 축소로 활용된 1x1 합성곱을 적용, 연산 효율 개선
- 입출력
  - 입력 : 이미지 / 3 x **244 x 244**
  - 출력 : 레이블 / 1 x 1024 벡터

#### 등장 배경

- 배치 정규화 방식으로 10+ 레이어 학습 가능
- 깊다고 무조건 더 잘 학습되는 것이 아님(단순히 깊게 하면 오히려 성능이 떨어짐)
  -> **최소한 작은 레이어 수준의 성능은 보장**(잔차블록의 핵심 아이디어)

#### Residual Block(잔차블록)

- 입력 X가 두 경러로 나뉘어 전달됨
  1. 변환 경로(원래 있던 일반적인 경로)(x->F(x))
  2. Shortcut 경로(입력 X 그대로 전달)
- 마지막에 두 값을 더함 : $output=F(x)+x$
- 학습이 잘 안 된다면 F(x)은 0과 비슷한 값이 될 수 있고 출력은 x가 됨
  -> **최소 성능 보장**

#### 💡 “최소 성능 보장”의 의미

만약 학습이 잘 안 되어서 𝐹(𝑥)가 거의 0에 가까워진다면,
**출력:**

$$
output=F(x)+x≈0+x=x
$$

-> 즉, 입력값이 그대로 다음 층으로 전달
이건 마치 그 블록이 아무 일도 하지 않은 것과 같은 상태(identity mapping)가 됨

#### ✅ 이게 왜 좋은가?

이 구조 덕분에 다음과 같은 이점이 생김 👇

1. 망가진 학습 방지 (Degradation 문제 해결)
   깊은 네트워크일수록 학습이 잘 안 되면서 성능이 오히려 나빠지는 경우가 있음
   하지만 Residual Block은 “적어도 입력을 그대로 전달할 수 있으니까”,
   학습이 완전히 실패해도 성능이 나빠지지 않고 최소한 기존 수준(x 그대로의 결과) 은 유지됨

2. 그라디언트 소실 완화 (Gradient Vanishing 완화)
   역전파 시, shortcut 경로 덕분에 gradient가 직접 입력층으로 흘러갈 수 있음
   따라서 𝐹(𝑥)가 잘 학습되지 않아도 네트워크 전체의 학습이 멈추지 않음

#### 일반 잔차 블록 vs 보틀넥 잔차 블록

> **연산 효율**을 위해 **보틀넥 잔차구조**를 도입 :
> 채널 사이즈 축소 후 연산 다시 입출력 해상도 맞추기 -> 연산 효율 높아짐!

#### Stem 구조

- 기존 모델의 효율성 레시피를 잘 활용
  1. 스템 구조를 모델 초기에 도입, 입구 데이터 해상도를 $\frac{1}{4}$ 로 줄이고 이후 잔차 블록 적용
  2. 여러 개의 FC 레이어를 제거하고(GoogleLeNet에서 제안), 전역 평균 풀링을 사용 -> 마지막 1개 FC만 적용

---

### 2-4. MobileNet

- 목표 : 모바일/임베디드 환경에서 구동 가능
  - 기존 합성곱은 공간(HxW)와 채널(C)를 동시 처리하여 연산량이 과도하게 요구됨
- MobileNet 핵심 아이디어 : 공간과 채널을 두 단계로 분리하여 처리
  1. 깊이별 합성곱 : 각 채널별 독립적 3x3 합성곱 수행
  2. 화소별 합성곡 : 1x1 합성곱을 채널방향으로 적용
- 효과
  - **연산량** 기존 대비 9배 가량 **절감**
  - 모델 상수 대폭 감소

---

## 3. CNN의 한계

### 3-1. CNN 구조의 장점

### 3-2. CNN의 핵심 한계

1. 데이터 순서 무시
2. 긴 거리 의존성 고려 부족
3. 픽셀 단위 복원 한계

---

## 4. 시퀀스 데이터 처리 : RNN

### 4-1. RNN

> 순차적 데이터를 처리하기 위해 고안된 신경망 구조

- 순차적 정보 반영 : 시간 /순서의 흐름을 반영할 수 있음
- 시계열/언어 데이터 적합 : 문장, 음성신호, 센서 데이터 등 시계열 데이터 처리에 관한 강력한 귀납 편향 제공

#### 과정

1. Input Chars
2. Input layer
3. Hidden layer
4. Output layer
5. Target Chars
   다시 2번 부터 수행하며 반복

#### 입출력 구조

one-to-one | 단일 입력 -> 단일 출력 | 이미지 -> 라벨(CNN 분류)
one-to-many | 단일 입력 -> 시퀀스 출력 | 이미지 -> 캡션 생성, 음악생성, 문장 생성
many-to-one | 시퀀스 입력 -> 단일 출력 | 문장 -> 감정 분류(긍/부정), 음성 -> 단일 라벨, 비디오 -> 행동 분류
many-to-money | 시퀀스 입력 -> 시퀀스 출력 | 기계 번역(영어 -> 한국어), 음성 -> 텍스트

### 4-2 단순 RNN 한계

기울기 폭발 혹은 소실 발생
-> 절삭! 하지만 기울기 소실을 막을 순 없다.

### 4-3. 대안 모델

LSTM -> 기울기 소실 방지

- cell state 추가
- 기울기 전파 시 선형가중치의 곱 이외의 덧셈 형태로 전달하여 기울기를 장기적으로 보존 가능
- 각 상태에서 기울기를 덧셈과 곱셈 경로로 분리 가능(소실 방지)

=> but, 정보 희석 문제의 한계
망각 게이트가 과거의 정보를 조금씩 줄임
-> 누적 효과로 과거 중요한 정보가 점차 희석되어 오래된 정보가 점차 약화됨

---

## 5. 긴거리 의존성 : 어텐션/ViT

### 5-1. 어텐션 메커니즘

- 픽셀 거리와 상관없이 유사한 패치가 이미지에 존재
- 관련 높은 패치/관련 낮은 패치 정보를 최종 결정에 반영하자!

#### 자기 어텐션(Self-Attention)

- 하나의 입력 안에서 패치 정보(쿼리/키/값)을 정의
- 같은 이미지 내 유사도(쿼리와 키 간 유사도) 반영
- 입력 내부 패치간 연결망 구축 -> 클러스터링 효과

> 클러스터링 : 서로 비스한 특성의 패치끼리 모여 그룹 형성

#### 교차 어텐션(Cross-Attention)

- 둘 이상의 이종 데이터에서 패치 정보(쿼리/키/값)을 정의
- 이종 데이터 간 유사도(쿼리와 키 간 유사도) 반영
- 서로 다른 입력 간 연결망 구축

### 5-2. ViT 위치 인코딩

- 패치 순서(위치) 정보 제공
  - 각 입력 토큰에 위치 정보를 담은 벡터를 추가
  - 다른 요소들과 어떤 위치 관계를 가지는지, 구조를 이해하기 위해서 순서 정보를 알아야 함

#### 위치 인코딩

1. 학습가능한 위치 인코딩 :

- 데이터에 알맞게 최적화
  - (+) 데이터 해상도가 바뀌어도 동일한 룰 적용
  - (-) 해상도가 바뀌면 다시 학습 필요

2. 사인파 인코딩

- 데이터에 알맞게 최적화
  - (+) 데이터 해상도가 바뀌어도 동일한 룰 적용
  - (-) 고정이라 데이터/과업에 특화된 방식이 아님

3. 상대 위치 인코딩

- 절대 위치가 아닌, 상대적 위치를 인코딩
  - (+) 해상도 변화에도 적용 가능
  - (-) 절대적 위치(예: 좌우 코너) 고려가 어려움

#### 인코더 내부 구조

- 정규화 - 다중헤드 어텐션 - 정규화 - 연결층으로 구성
- 인코더 L개 통과(일반적으로 12개 이상)

#### 전역 관계 학습

- CNN : 지역적 영역에서 수용영역을 넓혀 전역 이해
- ViT : 수용영역을 넓히지 않아도 전역 맥락 이해 가능

#### ViT vs ResNet

Q. ViT가 늘 CNN 모델보다 좋을까?
A. NO

> ImageNet의 경우, RestNet 성능이 더 우수
> . ImageNet-21K에서 사전학습하고 ImageNet미세 조정한 경우 ViT도 우수

- ViT는 **거대 데이터 세트 사전 학습 시** 우수

#### ViT 학습 시 유의점

- 막대한 상수를 보유, 정규화 기법/데이터 증강 기술이 매우 중요!
- 증류학습 기술이 효과적

#### Vision Transformer 트렌드

---
